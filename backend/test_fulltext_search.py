#!/usr/bin/env python3
"""
å…¨æ–‡æœç´¢æ€§èƒ½æµ‹è¯•
å¯¹æ¯”ILIKE vs PostgreSQLå…¨æ–‡æœç´¢çš„æ€§èƒ½å·®å¼‚
"""
import asyncio
import time

import httpx


async def test_search_performance():
    """æµ‹è¯•æœç´¢æ€§èƒ½"""
    print("=" * 60)
    print("ğŸ” å…¨æ–‡æœç´¢æ€§èƒ½æµ‹è¯•")
    print("=" * 60)

    search_queries = [
        "è¿›å‡»",
        "ä½ çš„åå­—",
        "ç”µå½±",
        "2020",
    ]

    async with httpx.AsyncClient() as client:
        for query in search_queries:
            print(f"\nğŸ“ æœç´¢å…³é”®è¯: '{query}'")

            # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼ˆæ— ç¼“å­˜ï¼‰
            start = time.time()
            response1 = await client.get(
                f"http://localhost:8000/api/v1/search?q={query}&page=1&page_size=10"
            )
            time1 = time.time() - start

            # ç¬¬äºŒæ¬¡è¯·æ±‚ï¼ˆç¼“å­˜ï¼‰
            start = time.time()
            response2 = await client.get(
                f"http://localhost:8000/api/v1/search?q={query}&page=1&page_size=10"
            )
            time2 = time.time() - start

            if response1.status_code == 200:
                data = response1.json()
                print(f"   âœ… æ‰¾åˆ°ç»“æœ: {data['total']}æ¡")
                print(f"   âœ… ç¬¬ä¸€æ¬¡è¯·æ±‚: {time1*1000:.0f}ms (å…¨æ–‡æœç´¢)")
                print(f"   âœ… ç¬¬äºŒæ¬¡è¯·æ±‚: {time2*1000:.0f}ms (ç¼“å­˜)")
                if time2 > 0:
                    print(f"   ğŸ“Š ç¼“å­˜æå‡: {time1/time2:.1f}x")

                # æ˜¾ç¤ºå‰3ä¸ªç»“æœ
                for i, item in enumerate(data["items"][:3], 1):
                    print(f"      {i}. {item['title']}")
            else:
                print(f"   âŒ æœç´¢å¤±è´¥: {response1.status_code}")


async def test_relevance_sorting():
    """æµ‹è¯•ç›¸å…³æ€§æ’åº"""
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç›¸å…³æ€§æ’åº")
    print("=" * 60)

    async with httpx.AsyncClient() as client:
        query = "è¿›å‡»"

        # æŒ‰ç›¸å…³æ€§æ’åº
        print(f"\nğŸ” æœç´¢ '{query}' (æŒ‰ç›¸å…³æ€§æ’åº)...")
        response = await client.get(
            f"http://localhost:8000/api/v1/search?q={query}&sort_by=relevance&page_size=5"
        )

        if response.status_code == 200:
            data = response.json()
            print(f"   âœ… ç»“æœæ•°é‡: {data['total']}")
            print("   ğŸ“‹ æŒ‰ç›¸å…³æ€§æ’åºçš„ç»“æœ:")
            for i, item in enumerate(data["items"], 1):
                print(f"      {i}. {item['title']}")
        else:
            print(f"   âŒ å¤±è´¥: {response.status_code}")


async def test_advanced_filters():
    """æµ‹è¯•é«˜çº§ç­›é€‰"""
    print("\n" + "=" * 60)
    print("ğŸ¯ æµ‹è¯•é«˜çº§ç­›é€‰")
    print("=" * 60)

    async with httpx.AsyncClient() as client:
        # ç»„åˆç­›é€‰ï¼šæœç´¢ + å¹´ä»½ + æœ€ä½è¯„åˆ†
        print("\nğŸ” ç»„åˆç­›é€‰: å…³é”®è¯='è¿›å‡»' + å¹´ä»½=2019 + è¯„åˆ†>=8.0")

        response = await client.get(
            "http://localhost:8000/api/v1/search?q=è¿›å‡»&year=2019&min_rating=8.0"
        )

        if response.status_code == 200:
            data = response.json()
            print(f"   âœ… æ‰¾åˆ°ç»“æœ: {data['total']}æ¡")
            for i, item in enumerate(data["items"][:3], 1):
                print(
                    f"      {i}. {item['title']} "
                    f"({item['release_year']}, è¯„åˆ†:{item['average_rating']})"
                )
        else:
            print(f"   âŒ å¤±è´¥: {response.status_code}")


async def test_search_features():
    """æµ‹è¯•æœç´¢ç‰¹æ€§"""
    print("\n" + "=" * 60)
    print("âœ¨ æœç´¢ç‰¹æ€§æµ‹è¯•")
    print("=" * 60)

    test_cases = [
        ("å•å­—æœç´¢", "å·¨"),
        ("å¤šå­—æœç´¢", "è¿›å‡»çš„å·¨äºº"),
        ("è‹±æ–‡æœç´¢", "movie"),
        ("æ•°å­—æœç´¢", "2020"),
    ]

    async with httpx.AsyncClient() as client:
        for name, query in test_cases:
            start = time.time()
            response = await client.get(
                f"http://localhost:8000/api/v1/search?q={query}&page_size=5"
            )
            elapsed = time.time() - start

            if response.status_code == 200:
                data = response.json()
                print(f"\n   {name}: '{query}'")
                print(f"      ç»“æœ: {data['total']}æ¡, è€—æ—¶: {elapsed*1000:.0f}ms")
            else:
                print(f"   âŒ {name} å¤±è´¥")


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    try:
        await test_search_performance()
        await test_relevance_sorting()
        await test_advanced_filters()
        await test_search_features()

        print("\n" + "=" * 60)
        print("âœ… å…¨æ–‡æœç´¢æµ‹è¯•å®Œæˆï¼")
        print("=" * 60)

        print("\nğŸ’¡ å…¨æ–‡æœç´¢ä¼˜åŠ¿:")
        print("   - âœ… ä½¿ç”¨GINç´¢å¼•ï¼Œæ€§èƒ½è¿œè¶…ILIKE")
        print("   - âœ… æ”¯æŒç›¸å…³æ€§æ’åºï¼ˆts_rankï¼‰")
        print("   - âœ… è‡ªåŠ¨æ›´æ–°ï¼ˆè§¦å‘å™¨ï¼‰")
        print("   - âœ… ç»„åˆé«˜çº§ç­›é€‰")
        print("   - âœ… ç¼“å­˜åŠ é€Ÿï¼ˆ5åˆ†é’ŸTTLï¼‰")

        print("\nğŸ“Š å¯ç”¨æ’åºæ–¹å¼:")
        print("   - created_at (é»˜è®¤)")
        print("   - view_count (çƒ­åº¦)")
        print("   - average_rating (è¯„åˆ†)")
        print("   - relevance (ç›¸å…³æ€§) â­ æ–°å¢")

    except httpx.ConnectError:
        print("\nâŒ é”™è¯¯: æ— æ³•è¿æ¥åˆ°åç«¯æœåŠ¡")
        print("   è¯·å…ˆå¯åŠ¨åç«¯: make backend-run")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())

