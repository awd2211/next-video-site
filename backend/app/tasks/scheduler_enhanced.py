"""
å¢å¼ºç‰ˆè°ƒåº¦ä»»åŠ¡ç³»ç»Ÿ
æ·»åŠ æ›´å¤šæ™ºèƒ½åŠŸèƒ½å’Œä¼˜åŒ–
"""

from datetime import datetime, timedelta, timezone
from typing import Dict, List

from celery import Task, group
from loguru import logger
from sqlalchemy import and_, func, or_, select

from app.celery_app import celery_app
from app.database import AsyncSessionLocal
from app.models.scheduling import (
    ContentSchedule,
    ScheduleHistory,
    ScheduleStatus,
    ScheduleContentType,
)
from app.services.scheduling_service import SchedulingService
from app.utils.admin_notification_service import AdminNotificationService


# ========== æ ¸å¿ƒè°ƒåº¦ä»»åŠ¡ ==========


@celery_app.task(
    name="scheduler.execute_due_schedules",
    bind=True,
    max_retries=3,
    default_retry_delay=60,
)
def execute_due_schedules(self):
    """
    æ‰§è¡Œæ‰€æœ‰åˆ°æœŸçš„è°ƒåº¦ä»»åŠ¡
    - æ¯åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
    - æ”¯æŒå¹¶å‘æ‰§è¡Œ
    - å¤±è´¥è‡ªåŠ¨é‡è¯•
    """
    import asyncio

    try:
        result = asyncio.run(_execute_due_schedules_async())

        # å¦‚æœæœ‰å¤±è´¥çš„ä»»åŠ¡ï¼Œè®°å½•æ—¥å¿—
        if result.get("failed_count", 0) > 0:
            logger.warning(
                f"Some schedules failed to execute: {result['failed_count']}/{result['total']}"
            )

        return result

    except Exception as exc:
        logger.exception(f"Critical error in execute_due_schedules: {exc}")
        # é‡è¯•ä»»åŠ¡
        raise self.retry(exc=exc)


async def _execute_due_schedules_async() -> Dict:
    """å¼‚æ­¥æ‰§è¡Œåˆ°æœŸä»»åŠ¡"""
    async with AsyncSessionLocal() as db:
        try:
            service = SchedulingService(db)

            # è·å–æ‰€æœ‰åˆ°æœŸä»»åŠ¡ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
            due_schedules = await service.get_due_schedules()

            if not due_schedules:
                return {"executed_count": 0, "failed_count": 0, "total": 0}

            logger.info(f"â° Found {len(due_schedules)} due schedules to execute")

            executed_count = 0
            failed_count = 0
            errors = []

            # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„æ‰§è¡Œ
            high_priority = [s for s in due_schedules if s.priority >= 80]
            normal_priority = [s for s in due_schedules if 50 <= s.priority < 80]
            low_priority = [s for s in due_schedules if s.priority < 50]

            # é«˜ä¼˜å…ˆçº§ä»»åŠ¡å…ˆæ‰§è¡Œ
            for schedule_group, priority_name in [
                (high_priority, "HIGH"),
                (normal_priority, "NORMAL"),
                (low_priority, "LOW"),
            ]:
                if not schedule_group:
                    continue

                logger.info(f"Executing {len(schedule_group)} {priority_name} priority tasks")

                for schedule in schedule_group:
                    try:
                        success, message = await service.execute_schedule(
                            schedule.id, executed_by=None
                        )

                        if success:
                            executed_count += 1
                            logger.info(
                                f"âœ… Schedule {schedule.id} executed: "
                                f"{schedule.content_type.value}:{schedule.content_id}"
                            )
                        else:
                            failed_count += 1
                            errors.append({
                                "schedule_id": schedule.id,
                                "content_type": schedule.content_type.value,
                                "content_id": schedule.content_id,
                                "error": message,
                            })
                            logger.error(f"âŒ Schedule {schedule.id} failed: {message}")

                    except Exception as e:
                        failed_count += 1
                        errors.append({
                            "schedule_id": schedule.id,
                            "error": str(e),
                        })
                        logger.exception(f"âŒ Exception executing schedule {schedule.id}: {e}")

            # å¦‚æœæœ‰å¤±è´¥çš„ä»»åŠ¡ï¼Œå‘é€é€šçŸ¥ç»™ç®¡ç†å‘˜
            if failed_count > 0:
                await _notify_execution_failures(db, errors)

            result = {
                "executed_count": executed_count,
                "failed_count": failed_count,
                "total": len(due_schedules),
                "errors": errors if errors else None,
            }

            logger.info(
                f"ğŸ“Š Execution summary: "
                f"âœ… {executed_count} succeeded, âŒ {failed_count} failed"
            )

            return result

        except Exception as e:
            logger.exception(f"Critical error in _execute_due_schedules_async: {e}")
            raise


async def _notify_execution_failures(db, errors: List[Dict]):
    """é€šçŸ¥ç®¡ç†å‘˜æ‰§è¡Œå¤±è´¥çš„ä»»åŠ¡"""
    try:
        message = f"è°ƒåº¦ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {len(errors)} ä¸ªä»»åŠ¡æœªèƒ½æˆåŠŸæ‰§è¡Œ"
        details = "\n".join([
            f"- Schedule #{e.get('schedule_id')}: {e.get('error', 'Unknown error')}"
            for e in errors[:10]  # åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
        ])

        await AdminNotificationService.notify_system_alert(
            db=db,
            alert_type="schedule_execution_failed",
            severity="high",
            message=message,
            details={"errors": errors[:10], "total_failed": len(errors)},
        )

        logger.info(f"Sent failure notification for {len(errors)} failed schedules")

    except Exception as e:
        logger.exception(f"Failed to send execution failure notification: {e}")


# ========== æ™ºèƒ½è°ƒåº¦ä¼˜åŒ– ==========


@celery_app.task(name="scheduler.optimize_schedule_times")
def optimize_schedule_times():
    """
    æ™ºèƒ½ä¼˜åŒ–è°ƒåº¦æ—¶é—´
    - åˆ†æå†å²æ•°æ®
    - é¿å¼€é«˜å³°æ—¶æ®µ
    - å¹³è¡¡æœåŠ¡å™¨è´Ÿè½½
    """
    import asyncio
    return asyncio.run(_optimize_schedule_times_async())


async def _optimize_schedule_times_async() -> Dict:
    """å¼‚æ­¥ä¼˜åŒ–è°ƒåº¦æ—¶é—´"""
    async with AsyncSessionLocal() as db:
        try:
            # è·å–æœªæ¥24å°æ—¶çš„å¾…æ‰§è¡Œä»»åŠ¡
            now = datetime.now(timezone.utc)
            future_24h = now + timedelta(hours=24)

            result = await db.execute(
                select(ContentSchedule)
                .where(
                    and_(
                        ContentSchedule.status == ScheduleStatus.PENDING,
                        ContentSchedule.scheduled_time.between(now, future_24h),
                    )
                )
                .order_by(ContentSchedule.scheduled_time)
            )

            schedules = list(result.scalars().all())

            if len(schedules) < 10:
                return {"message": "Not enough schedules to optimize", "count": len(schedules)}

            # æŒ‰å°æ—¶åˆ†ç»„ç»Ÿè®¡
            hourly_counts = {}
            for schedule in schedules:
                hour = schedule.scheduled_time.hour
                hourly_counts[hour] = hourly_counts.get(hour, 0) + 1

            # æ‰¾å‡ºè´Ÿè½½æœ€é«˜çš„å°æ—¶
            max_load_hour = max(hourly_counts, key=hourly_counts.get)
            max_load = hourly_counts[max_load_hour]

            # å¦‚æœæŸä¸ªå°æ—¶è¶…è¿‡10ä¸ªä»»åŠ¡ï¼Œå»ºè®®åˆ†æ•£
            optimized_count = 0
            if max_load > 10:
                logger.info(
                    f"High load detected at hour {max_load_hour}: {max_load} tasks"
                )

                # TODO: å®ç°ä»»åŠ¡é‡æ–°åˆ†é…é€»è¾‘
                # è¿™é‡Œå¯ä»¥æ ¹æ®ä¸šåŠ¡éœ€æ±‚è‡ªåŠ¨è°ƒæ•´æ—¶é—´

                optimized_count = 0  # å®é™…è°ƒæ•´çš„ä»»åŠ¡æ•°

            return {
                "total_schedules": len(schedules),
                "hourly_distribution": hourly_counts,
                "max_load_hour": max_load_hour,
                "max_load": max_load,
                "optimized_count": optimized_count,
            }

        except Exception as e:
            logger.exception(f"Error in optimize_schedule_times: {e}")
            return {"error": str(e)}


# ========== å†²çªæ£€æµ‹ ==========


@celery_app.task(name="scheduler.detect_conflicts")
def detect_conflicts():
    """
    æ£€æµ‹è°ƒåº¦å†²çª
    - ç›¸åŒå†…å®¹é‡å¤è°ƒåº¦
    - æ—¶é—´è¿‡äºæ¥è¿‘çš„è°ƒåº¦
    - èµ„æºå†²çª
    """
    import asyncio
    return asyncio.run(_detect_conflicts_async())


async def _detect_conflicts_async() -> Dict:
    """å¼‚æ­¥æ£€æµ‹å†²çª"""
    async with AsyncSessionLocal() as db:
        try:
            now = datetime.now(timezone.utc)
            future_7days = now + timedelta(days=7)

            # è·å–æœªæ¥7å¤©çš„å¾…æ‰§è¡Œä»»åŠ¡
            result = await db.execute(
                select(ContentSchedule)
                .where(
                    and_(
                        ContentSchedule.status == ScheduleStatus.PENDING,
                        ContentSchedule.scheduled_time.between(now, future_7days),
                    )
                )
                .order_by(ContentSchedule.content_type, ContentSchedule.content_id)
            )

            schedules = list(result.scalars().all())

            conflicts = []

            # æ£€æµ‹1: ç›¸åŒå†…å®¹çš„é‡å¤è°ƒåº¦
            content_map = {}
            for schedule in schedules:
                key = f"{schedule.content_type.value}:{schedule.content_id}"
                if key not in content_map:
                    content_map[key] = []
                content_map[key].append(schedule)

            for key, schedule_list in content_map.items():
                if len(schedule_list) > 1:
                    conflicts.append({
                        "type": "duplicate_content",
                        "content": key,
                        "schedules": [s.id for s in schedule_list],
                        "times": [s.scheduled_time.isoformat() for s in schedule_list],
                    })

            # æ£€æµ‹2: åŒä¸€æ—¶é—´ï¼ˆ5åˆ†é’Ÿå†…ï¼‰çš„è¿‡å¤šä»»åŠ¡
            time_buckets = {}
            for schedule in schedules:
                # æŒ‰5åˆ†é’Ÿåˆ†æ¡¶
                bucket_time = schedule.scheduled_time.replace(
                    minute=(schedule.scheduled_time.minute // 5) * 5,
                    second=0,
                    microsecond=0
                )
                bucket_key = bucket_time.isoformat()

                if bucket_key not in time_buckets:
                    time_buckets[bucket_key] = []
                time_buckets[bucket_key].append(schedule)

            for bucket_key, schedule_list in time_buckets.items():
                if len(schedule_list) > 5:  # 5åˆ†é’Ÿå†…è¶…è¿‡5ä¸ªä»»åŠ¡
                    conflicts.append({
                        "type": "high_concurrency",
                        "time_bucket": bucket_key,
                        "count": len(schedule_list),
                        "schedules": [s.id for s in schedule_list],
                    })

            # å¦‚æœå‘ç°å†²çªï¼Œå‘é€é€šçŸ¥
            if conflicts:
                await _notify_conflicts(db, conflicts)

            return {
                "total_checked": len(schedules),
                "conflicts_found": len(conflicts),
                "conflicts": conflicts,
            }

        except Exception as e:
            logger.exception(f"Error in detect_conflicts: {e}")
            return {"error": str(e)}


async def _notify_conflicts(db, conflicts: List[Dict]):
    """é€šçŸ¥ç®¡ç†å‘˜å‘ç°çš„å†²çª"""
    try:
        message = f"æ£€æµ‹åˆ° {len(conflicts)} ä¸ªè°ƒåº¦å†²çª"

        await AdminNotificationService.notify_system_alert(
            db=db,
            alert_type="schedule_conflict",
            severity="medium",
            message=message,
            details={"conflicts": conflicts},
        )

        logger.info(f"Sent conflict notification: {len(conflicts)} conflicts")

    except Exception as e:
        logger.exception(f"Failed to send conflict notification: {e}")


# ========== æ¯æ—¥æŠ¥å‘Šç”Ÿæˆ ==========


@celery_app.task(name="scheduler.generate_daily_report")
def generate_daily_report():
    """
    ç”Ÿæˆæ¯æ—¥è°ƒåº¦æŠ¥å‘Š
    - æ˜¨æ—¥æ‰§è¡Œç»Ÿè®¡
    - æˆåŠŸç‡åˆ†æ
    - ä»Šæ—¥å¾…æ‰§è¡Œä»»åŠ¡
    - å¼‚å¸¸é¢„è­¦
    """
    import asyncio
    return asyncio.run(_generate_daily_report_async())


async def _generate_daily_report_async() -> Dict:
    """å¼‚æ­¥ç”Ÿæˆæ¯æ—¥æŠ¥å‘Š"""
    async with AsyncSessionLocal() as db:
        try:
            now = datetime.now(timezone.utc)
            yesterday_start = (now - timedelta(days=1)).replace(
                hour=0, minute=0, second=0, microsecond=0
            )
            yesterday_end = yesterday_start + timedelta(days=1)
            today_end = now + timedelta(days=1)

            # ç»Ÿè®¡æ˜¨æ—¥æ•°æ®
            yesterday_published = await db.execute(
                select(func.count(ContentSchedule.id)).where(
                    and_(
                        ContentSchedule.status == ScheduleStatus.PUBLISHED,
                        ContentSchedule.actual_publish_time >= yesterday_start,
                        ContentSchedule.actual_publish_time < yesterday_end,
                    )
                )
            )
            published_count = yesterday_published.scalar() or 0

            yesterday_failed = await db.execute(
                select(func.count(ContentSchedule.id)).where(
                    and_(
                        ContentSchedule.status == ScheduleStatus.FAILED,
                        ContentSchedule.updated_at >= yesterday_start,
                        ContentSchedule.updated_at < yesterday_end,
                    )
                )
            )
            failed_count = yesterday_failed.scalar() or 0

            # è®¡ç®—æˆåŠŸç‡
            total_executed = published_count + failed_count
            success_rate = (
                (published_count / total_executed * 100) if total_executed > 0 else 0
            )

            # ä»Šæ—¥å¾…æ‰§è¡Œä»»åŠ¡
            today_pending = await db.execute(
                select(func.count(ContentSchedule.id)).where(
                    and_(
                        ContentSchedule.status == ScheduleStatus.PENDING,
                        ContentSchedule.scheduled_time >= now,
                        ContentSchedule.scheduled_time < today_end,
                    )
                )
            )
            pending_today = today_pending.scalar() or 0

            # è¿‡æœŸæœªæ‰§è¡Œä»»åŠ¡
            overdue = await db.execute(
                select(func.count(ContentSchedule.id)).where(
                    and_(
                        ContentSchedule.status == ScheduleStatus.PENDING,
                        ContentSchedule.scheduled_time < now,
                    )
                )
            )
            overdue_count = overdue.scalar() or 0

            report = {
                "date": now.date().isoformat(),
                "yesterday": {
                    "published": published_count,
                    "failed": failed_count,
                    "total": total_executed,
                    "success_rate": round(success_rate, 2),
                },
                "today": {
                    "pending": pending_today,
                    "overdue": overdue_count,
                },
            }

            # å‘é€æŠ¥å‘Šé€šçŸ¥
            await _send_daily_report(db, report)

            logger.info(f"ğŸ“Š Daily report generated: {report}")

            return report

        except Exception as e:
            logger.exception(f"Error generating daily report: {e}")
            return {"error": str(e)}


async def _send_daily_report(db, report: Dict):
    """å‘é€æ¯æ—¥æŠ¥å‘Šç»™ç®¡ç†å‘˜"""
    try:
        yesterday_data = report["yesterday"]
        today_data = report["today"]

        message = f"""
ğŸ“Š è°ƒåº¦ç³»ç»Ÿæ¯æ—¥æŠ¥å‘Š ({report['date']})

ğŸ“ˆ æ˜¨æ—¥æ‰§è¡Œæƒ…å†µ:
  âœ… æˆåŠŸ: {yesterday_data['published']}
  âŒ å¤±è´¥: {yesterday_data['failed']}
  ğŸ“Š æˆåŠŸç‡: {yesterday_data['success_rate']}%

â° ä»Šæ—¥è®¡åˆ’:
  ğŸ“… å¾…æ‰§è¡Œ: {today_data['pending']}
  âš ï¸ è¿‡æœŸæœªæ‰§è¡Œ: {today_data['overdue']}
""".strip()

        await AdminNotificationService.notify_system_alert(
            db=db,
            alert_type="daily_schedule_report",
            severity="info",
            message="è°ƒåº¦ç³»ç»Ÿæ¯æ—¥æŠ¥å‘Š",
            details=report,
        )

        logger.info("Daily report sent to admins")

    except Exception as e:
        logger.exception(f"Failed to send daily report: {e}")


# ========== å¥åº·æ£€æŸ¥ ==========


@celery_app.task(name="scheduler.health_check")
def health_check():
    """
    è°ƒåº¦ç³»ç»Ÿå¥åº·æ£€æŸ¥
    - æ£€æŸ¥æ˜¯å¦æœ‰é•¿æ—¶é—´å¡ä½çš„ä»»åŠ¡
    - æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸çŠ¶æ€
    - æ£€æŸ¥æ•°æ®åº“è¿æ¥
    """
    import asyncio
    return asyncio.run(_health_check_async())


async def _health_check_async() -> Dict:
    """å¼‚æ­¥å¥åº·æ£€æŸ¥"""
    async with AsyncSessionLocal() as db:
        try:
            issues = []

            # æ£€æŸ¥1: æ˜¯å¦æœ‰é•¿æ—¶é—´å¤„äºpendingä½†å·²è¿‡æœŸçš„ä»»åŠ¡
            now = datetime.now(timezone.utc)
            one_hour_ago = now - timedelta(hours=1)

            stuck_schedules = await db.execute(
                select(func.count(ContentSchedule.id)).where(
                    and_(
                        ContentSchedule.status == ScheduleStatus.PENDING,
                        ContentSchedule.scheduled_time < one_hour_ago,
                    )
                )
            )
            stuck_count = stuck_schedules.scalar() or 0

            if stuck_count > 0:
                issues.append({
                    "type": "stuck_schedules",
                    "count": stuck_count,
                    "message": f"{stuck_count} schedules stuck for over 1 hour",
                })

            # æ£€æŸ¥2: å¤±è´¥ç‡æ˜¯å¦å¼‚å¸¸é«˜
            recent_failures = await db.execute(
                select(func.count(ContentSchedule.id)).where(
                    and_(
                        ContentSchedule.status == ScheduleStatus.FAILED,
                        ContentSchedule.updated_at >= one_hour_ago,
                    )
                )
            )
            recent_failed = recent_failures.scalar() or 0

            if recent_failed > 10:
                issues.append({
                    "type": "high_failure_rate",
                    "count": recent_failed,
                    "message": f"{recent_failed} failures in the last hour",
                })

            health_status = "healthy" if not issues else "unhealthy"

            result = {
                "status": health_status,
                "timestamp": now.isoformat(),
                "issues": issues,
            }

            # å¦‚æœæœ‰é—®é¢˜ï¼Œå‘é€å‘Šè­¦
            if issues:
                await _notify_health_issues(db, issues)
                logger.warning(f"âš ï¸ Health check found issues: {issues}")
            else:
                logger.info("âœ… Health check passed")

            return result

        except Exception as e:
            logger.exception(f"Error in health check: {e}")
            return {"status": "error", "error": str(e)}


async def _notify_health_issues(db, issues: List[Dict]):
    """é€šçŸ¥ç®¡ç†å‘˜å¥åº·æ£€æŸ¥å‘ç°çš„é—®é¢˜"""
    try:
        message = f"è°ƒåº¦ç³»ç»Ÿå¥åº·æ£€æŸ¥å‘ç° {len(issues)} ä¸ªé—®é¢˜"

        await AdminNotificationService.notify_system_alert(
            db=db,
            alert_type="scheduler_health_issue",
            severity="high",
            message=message,
            details={"issues": issues},
        )

        logger.info(f"Sent health issue notification: {len(issues)} issues")

    except Exception as e:
        logger.exception(f"Failed to send health issue notification: {e}")
