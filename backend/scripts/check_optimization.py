#!/usr/bin/env python3
"""
ä¼˜åŒ–æ£€æŸ¥å·¥å…· - æ£€æŸ¥ä»£ç æ˜¯å¦éµå¾ªæ€§èƒ½æœ€ä½³å®žè·µ

Usage:
    python scripts/check_optimization.py
    python scripts/check_optimization.py --path app/api
    python scripts/check_optimization.py --fix
"""

import argparse
import ast
import os
import re
from pathlib import Path

from loguru import logger


class OptimizationChecker:
    """ä¼˜åŒ–æ£€æŸ¥å™¨"""

    def __init__(self, base_path: str = "app", auto_fix: bool = False):
        self.base_path = Path(base_path)
        self.auto_fix = auto_fix
        self.issues = []
        self.warnings = []
        self.good_practices = []

    def check_all(self):
        """æ£€æŸ¥æ‰€æœ‰Pythonæ–‡ä»¶"""
        logger.info("ðŸ” Checking optimization best practices...\n")

        python_files = list(self.base_path.rglob("*.py"))
        logger.info(f"Found {len(python_files)} Python files\n")

        for file_path in python_files:
            if "__pycache__" in str(file_path):
                continue

            self.check_file(file_path)

        self.print_summary()

    def check_file(self, file_path: Path):
        """æ£€æŸ¥å•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # å„ç§æ£€æŸ¥
            self.check_rate_limiting(file_path, content)
            self.check_caching(file_path, content)
            self.check_n_plus_one(file_path, content)
            self.check_batch_operations(file_path, content)
            self.check_error_handling(file_path, content)
            self.check_profiling(file_path, content)

        except Exception as e:
            logger.error(f"Error checking {file_path}: {e}")

    def check_rate_limiting(self, file_path: Path, content: str):
        """æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†é™æµ"""
        # æ£€æŸ¥APIè·¯ç”±æ–‡ä»¶
        if "/api/" in str(file_path) and "@router." in content:
            # æŸ¥æ‰¾è·¯ç”±è£…é¥°å™¨
            route_pattern = r"@router\.(get|post|put|delete|patch)\("
            routes = re.findall(route_pattern, content)

            if routes:
                # æ£€æŸ¥æ˜¯å¦æœ‰limiterè£…é¥°å™¨
                has_limiter = "@limiter.limit" in content

                if not has_limiter and len(routes) > 0:
                    self.warnings.append(
                        f"âš ï¸  {file_path}: {len(routes)} routes without rate limiting"
                    )
                    logger.warning(
                        f"  {file_path.name}: {len(routes)} routes without @limiter.limit"
                    )
                else:
                    self.good_practices.append(
                        f"âœ… {file_path.name}: Rate limiting enabled"
                    )

    def check_caching(self, file_path: Path, content: str):
        """æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ç¼“å­˜"""
        if "/api/" in str(file_path):
            # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®åº“æŸ¥è¯¢
            has_query = "select(" in content or "db.execute" in content

            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            has_cache = "Cache.get" in content or "@cache_result" in content

            if has_query and not has_cache:
                self.warnings.append(
                    f"âš ï¸  {file_path}: Database queries without caching"
                )
                logger.warning(f"  {file_path.name}: Consider adding caching")

    def check_n_plus_one(self, file_path: Path, content: str):
        """æ£€æŸ¥å¯èƒ½çš„N+1æŸ¥è¯¢é—®é¢˜"""
        if "select(" in content:
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†selectinloadæˆ–joinedload
            has_preload = (
                "selectinload" in content
                or "joinedload" in content
                or "subqueryload" in content
            )

            # æ£€æŸ¥æ˜¯å¦æœ‰å…³ç³»è®¿é—®
            has_relationship_access = re.search(
                r"\.\w+\.(categories|tags|actors|directors|comments)", content
            )

            if has_relationship_access and not has_preload:
                self.issues.append(
                    f"âŒ {file_path}: Possible N+1 query - use selectinload()"
                )
                logger.error(
                    f"  {file_path.name}: Possible N+1 query - missing selectinload"
                )
            elif has_preload:
                self.good_practices.append(
                    f"âœ… {file_path.name}: Using eager loading"
                )

    def check_batch_operations(self, file_path: Path, content: str):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨æ‰¹é‡æ“ä½œ"""
        # æ£€æŸ¥å¾ªçŽ¯ä¸­çš„æ•°æ®åº“æ“ä½œ
        loop_db_pattern = r"for .+ in .+:\s+.*db\.(add|execute|delete)"

        if re.search(loop_db_pattern, content, re.MULTILINE):
            self.warnings.append(
                f"âš ï¸  {file_path}: Loop with DB operations - consider batch processing"
            )
            logger.warning(
                f"  {file_path.name}: Consider using BatchProcessor for loops"
            )

    def check_error_handling(self, file_path: Path, content: str):
        """æ£€æŸ¥é”™è¯¯å¤„ç†"""
        # æ£€æŸ¥æ˜¯å¦æœ‰è£¸except
        if re.search(r"except\s*:", content):
            self.warnings.append(f"âš ï¸  {file_path}: Bare except clause found")
            logger.warning(f"  {file_path.name}: Avoid bare except: clauses")

        # æ£€æŸ¥æ˜¯å¦è®°å½•å¼‚å¸¸
        has_try = "try:" in content
        has_logger = "logger." in content or "logging." in content

        if has_try and not has_logger:
            self.warnings.append(
                f"âš ï¸  {file_path}: Try/except without logging"
            )

    def check_profiling(self, file_path: Path, content: str):
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥æ·»åŠ æ€§èƒ½åˆ†æž"""
        # æ£€æŸ¥å¤æ‚å‡½æ•°ï¼ˆè¶…è¿‡50è¡Œï¼‰
        try:
            tree = ast.parse(content)

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    # è®¡ç®—å‡½æ•°è¡Œæ•°
                    if hasattr(node, "lineno") and hasattr(node, "end_lineno"):
                        lines = node.end_lineno - node.lineno

                        if lines > 50:
                            # æ£€æŸ¥æ˜¯å¦æœ‰profilerè£…é¥°å™¨
                            has_profiler = any(
                                "PerformanceProfiler" in ast.get_source_segment(content, d)
                                or "@profile" in ast.get_source_segment(content, d)
                                for d in node.decorator_list
                                if ast.get_source_segment(content, d)
                            )

                            if not has_profiler:
                                self.warnings.append(
                                    f"âš ï¸  {file_path}:{node.lineno}: Function '{node.name}' "
                                    f"({lines} lines) could benefit from profiling"
                                )

        except SyntaxError:
            pass  # è·³è¿‡è¯­æ³•é”™è¯¯çš„æ–‡ä»¶

    def print_summary(self):
        """æ‰“å°æ£€æŸ¥æ‘˜è¦"""
        logger.info("\n" + "=" * 80)
        logger.info("ðŸ“Š Optimization Check Summary")
        logger.info("=" * 80)

        # å¥½çš„å®žè·µ
        if self.good_practices:
            logger.info(f"\nâœ… GOOD PRACTICES ({len(self.good_practices)}):")
            for practice in self.good_practices[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                logger.info(f"  {practice}")
            if len(self.good_practices) > 10:
                logger.info(f"  ... and {len(self.good_practices) - 10} more")

        # è­¦å‘Š
        if self.warnings:
            logger.warning(f"\nâš ï¸  WARNINGS ({len(self.warnings)}):")
            for warning in self.warnings:
                logger.warning(f"  {warning}")

        # é—®é¢˜
        if self.issues:
            logger.error(f"\nâŒ ISSUES ({len(self.issues)}):")
            for issue in self.issues:
                logger.error(f"  {issue}")

        # å»ºè®®
        logger.info("\n" + "=" * 80)
        logger.info("ðŸ’¡ Recommendations:")
        logger.info("=" * 80)

        recommendations = []

        if any("rate limiting" in str(w).lower() for w in self.warnings):
            recommendations.append(
                "1. Add @limiter.limit() decorators to API endpoints\n"
                "   Example: @limiter.limit(RateLimitPresets.MODERATE)"
            )

        if any("n+1" in str(i).lower() for i in self.issues):
            recommendations.append(
                "2. Fix N+1 queries using selectinload()\n"
                "   Example: query.options(selectinload(Video.categories))"
            )

        if any("batch" in str(w).lower() for w in self.warnings):
            recommendations.append(
                "3. Use BatchProcessor for bulk operations\n"
                "   Example: await BatchProcessor.batch_insert(db, Model, items)"
            )

        if any("caching" in str(w).lower() for w in self.warnings):
            recommendations.append(
                "4. Add caching for frequently accessed data\n"
                "   Example: @cache_result('key', ttl=300)"
            )

        for i, rec in enumerate(recommendations, 1):
            logger.info(f"\n{rec}")

        # æ€»åˆ†
        total = len(self.good_practices) + len(self.warnings) + len(self.issues)
        if total > 0:
            score = (len(self.good_practices) / total) * 100
            logger.info(f"\nOptimization Score: {score:.1f}%")

            if score >= 80:
                logger.info("Grade: A - Excellent! ðŸŒŸ")
            elif score >= 60:
                logger.info("Grade: B - Good, but room for improvement")
            elif score >= 40:
                logger.info("Grade: C - Needs attention")
            else:
                logger.info("Grade: D - Major improvements needed")

        logger.info("\n" + "=" * 80 + "\n")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Optimization Best Practices Checker")
    parser.add_argument(
        "--path", default="app", help="Path to check (default: app)"
    )
    parser.add_argument(
        "--fix", action="store_true", help="Auto-fix issues (not implemented yet)"
    )

    args = parser.parse_args()

    checker = OptimizationChecker(base_path=args.path, auto_fix=args.fix)
    checker.check_all()


if __name__ == "__main__":
    main()
